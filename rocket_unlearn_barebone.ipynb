{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad7fe9f",
   "metadata": {},
   "source": [
    "importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "517452e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataset import *\n",
    "from model import ResNet18\n",
    "from unlearn import *\n",
    "from metrics import UnLearningScore\n",
    "from utils import *\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b02441",
   "metadata": {},
   "source": [
    "Load/Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f65344b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CustomCIFAR100(root='.', train=True, download=True, transform=transform_train)\n",
    "valid_ds = CustomCIFAR100(root='.', train=False, download=True, transform=transform_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199d92c6",
   "metadata": {},
   "source": [
    "Split into forget and retain subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca46bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor([label for _, label, _ in train_ds])\n",
    "valid_labels = torch.tensor([label for _, label, _ in valid_ds])\n",
    "\n",
    "forget_train_ds = Subset(train_ds, torch.where(train_labels == 69)[0])\n",
    "forget_valid_ds = Subset(valid_ds, torch.where(valid_labels == 69)[0])\n",
    "\n",
    "retain_train_ds = Subset(train_ds, torch.where(train_labels != 69)[0])\n",
    "retain_valid_ds = Subset(valid_ds, torch.where(valid_labels != 69)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0fec2",
   "metadata": {},
   "source": [
    "Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16638c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, num_workers=num_workers, pin_memory=False, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size, num_workers=num_workers, pin_memory=False)\n",
    "\n",
    "retain_train_dl = DataLoader(retain_train_ds, batch_size, num_workers=num_workers, pin_memory=True, shuffle = True)\n",
    "retain_valid_dl = DataLoader(retain_valid_ds, batch_size, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "forget_train_dl = DataLoader(forget_train_ds, batch_size, num_workers=num_workers, pin_memory=True, shuffle = True)\n",
    "forget_valid_dl = DataLoader(forget_valid_ds, batch_size, num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815403e",
   "metadata": {},
   "source": [
    "## Fully Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_trained_teacher = ResNet18(num_classes = 20, pretrained = False).to(device)\n",
    "\n",
    "# Training\n",
    "# history = fit_one_cycle(5, full_trained_teacher, train_dl, valid_dl, device = device)\n",
    "\n",
    "# Loading\n",
    "full_trained_teacher.load_state_dict(torch.load(\"ResNET18_CIFAR100Super20_Pretrained_ALL_CLASSES_5_Epochs.pt\", map_location = device))\n",
    "\n",
    "# Saving\n",
    "# torch.save(full_trained_teacher.state_dict(), \"ResNET18_CIFAR100Super20_Pretrained_ALL_CLASSES_5_Epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of Fully trained model on retain set\n",
    "evaluate(full_trained_teacher, retain_valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdc530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of Fully trained model on forget set\n",
    "evaluate(full_trained_teacher, forget_valid_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60da493b",
   "metadata": {},
   "source": [
    "## Gold Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141500d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Foopy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Foopy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Foopy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], last_lr: 0.00100, train_loss: 1.2316, val_loss: 1.0841, val_acc: 66.8190\n",
      "Epoch [1], last_lr: 0.00100, train_loss: 0.7730, val_loss: 0.8073, val_acc: 73.9187\n",
      "Epoch [2], last_lr: 0.00100, train_loss: 0.5319, val_loss: 0.9867, val_acc: 76.6631\n",
      "Epoch [3], last_lr: 0.00100, train_loss: 0.3863, val_loss: 0.7015, val_acc: 78.9410\n",
      "Epoch [4], last_lr: 0.00100, train_loss: 0.2671, val_loss: 0.9546, val_acc: 76.3636\n"
     ]
    }
   ],
   "source": [
    "gold_model = ResNet18(num_classes = 20, pretrained = True).to(device)\n",
    "\n",
    "# Training\n",
    "# history = fit_one_cycle(5, gold_model, retain_train_dl, retain_valid_dl, device = device)\n",
    "\n",
    "# Loading\n",
    "gold_model.load_state_dict(torch.load(\"ResNET18_CIFAR100Super20_Pretrained_Gold_Class69_5_Epochs.pt\", map_location = device))\n",
    "\n",
    "# Saving\n",
    "# torch.save(gold_model.state_dict(), \"ResNET18_CIFAR100Super20_Pretrained_Gold_Class69_5_Epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f033d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loss': 0.9545837044715881, 'Acc': 76.36357879638672}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of Gold model on retain set\n",
    "evaluate(gold_model, retain_valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba63aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loss': 10.044050216674805, 'Acc': 1.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance of Gold model on forget set\n",
    "evaluate(gold_model, forget_valid_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0531f6f1",
   "metadata": {},
   "source": [
    "## Unlearn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2841029f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Unlearning Loss 0.07968588173389435\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(num_classes = 20, pretrained = False).to(device)\n",
    "unlearning_teacher = ResNet18(num_classes = 20, pretrained = False).to(device)\n",
    "\n",
    "# Training\n",
    "# model.load_state_dict(torch.load(\"ResNET18_CIFAR100Super20_Pretrained_ALL_CLASSES_5_Epochs.pt\", map_location = device))\n",
    "# blindspot_unlearner(model = model, unlearning_teacher = unlearning_teacher, full_trained_teacher = full_trained_teacher, \n",
    "#                     retain_data = retain_train_ds, forget_data = forget_train_ds, epochs = 1, lr = 0.0001, \n",
    "#                     batch_size = batch_size, num_workers = num_workers, device = device)\n",
    "\n",
    "# Loading\n",
    "model.load_state_dict(torch.load(\"ResNET18_CIFAR100Super20_Pretrained_Forget_Class69_1_Epochs.pt\", map_location = device))\n",
    "\n",
    "# Saving\n",
    "# torch.save(model.state_dict(), \"ResNET18_CIFAR100Super20_Pretrained_Forget_Class69_1_Epochs.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "06701e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loss': 0.68032306432724, 'Acc': 80.65811920166016}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performance of unlearned model on retain set\n",
    "evaluate(model, retain_valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75166746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Loss': 2.747257947921753, 'Acc': 21.0}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# performance of unlearned model on forget set\n",
    "evaluate(model, forget_valid_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b6452",
   "metadata": {},
   "source": [
    "### Measure ZRF (Unlearning Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Foopy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\functional.py:3384: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Score: 0.7626310586929321\n",
      "Our Score: 0.9788732528686523\n",
      "Gold Score: 0.8664335012435913\n",
      "JS Div: 0.08812201023101807\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial Score: {}\".format(UnLearningScore(full_trained_teacher, unlearning_teacher, forget_valid_dl, batch_size, device)))\n",
    "print(\"Our Score: {}\".format(UnLearningScore(model, unlearning_teacher, forget_valid_dl, batch_size, device)))\n",
    "print(\"Gold Score: {}\".format(UnLearningScore(gold_model, unlearning_teacher, forget_valid_dl, batch_size, device)))\n",
    "print(\"JS Div: {}\".format(1-UnLearningScore(gold_model, model, forget_valid_dl, batch_size, device)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
